{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extension of the Project for CS 401 Applied Data Analysis course\n",
    "\n",
    "By: Team Data Nuage\n",
    "\n",
    "Paper: [Link](https://cs.stanford.edu/people/jure/pubs/triads-chi10.pdf)\n",
    "\n",
    "<hr style=\"border:5px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extension Description\n",
    "\n",
    "### Title: Behaviour of edge signs in economic and non-living entities networks\n",
    "\n",
    "#### Abstract\n",
    "\n",
    "The analysis performed in this [work](https://cs.stanford.edu/people/jure/pubs/triads-chi10.pdf) enabled the authors to evaluate the social psychological theories of balance and status in social networks. This work allows us to better understand and predict the signs of relationships in social networks. The theories have been formulated on humans and were tested on them and the [paper](https://cs.stanford.edu/people/jure/pubs/triads-chi10.pdf) tests them on the connections formed by humans on social networking sites. To take this analysis one step further, we would like to observe how well these social theories hold up when the network context has changed. Moreover, we would also like to perceive the similarities and differences in analyzing the signs of relationships between entities created by people instead of the people themselves. For these two cases, we will be using a bitcoin dataset to provide a network in a financial setting (economic context) and a Reddit dataset that presents a graph of subreddits created by users. Our analysis would include observing and also presenting statistics about the number of balanced and unbalanced triads in the data and thereby interpreting the validity of balance and status theory and corroborate or contradicting the claims of the authors made in the original paper.\n",
    "\n",
    "#### Research Questions\n",
    "\n",
    "In this extension, we want to verify and discuss the generalization of the balance and status theory on other types of networks. Specifically, we want to answer the following questions\n",
    "\n",
    "1. Whether the proposed theories on balance and status can be extended to `networks created based on monetary/profit relationships` **instead of** of `relationships created as social connections in slashdot data` i.e. will the relations between people (users) still follow the balance and status theory even when there is a direct cash transaction involved?\n",
    "2. Secondly, will the theories of balance and status propagate from the **individual human relations** to the **nonliving entities** that are created and controlled by living entities? Here the graph is formed by the units that are created by humans and signs are based on relations between these units. Thus, we want to verify if the collective behavior of humans in those units follows the same laws as individuals. The datasets in the paper are representative of the direct opinion of one person on the other, unlike the Reddit dataset where the relation is between human-created units (that carry the opinion of humans).\n",
    "\n",
    "#### Proposed datasets\n",
    "\n",
    "For this extension, we are going to use the following two datasets.\n",
    "\n",
    "In order to answer the first question we use [soc-sign-bitcoinalpha.csv.gz](http://snap.stanford.edu/data/soc-sign-bitcoin-alpha.html) dataset and use [soc-redditHyperlinks-body.tsv](http://snap.stanford.edu/data/soc-RedditHyperlinks.html) for the second question.\n",
    "\n",
    "The signed network in the bitcoin transaction dataset is created by users trading Bitcoins, who rate other members on a scale of -10 (total distrust) to +10 (total trust) to prevent transactions with fraudulent and risky users.\n",
    "\n",
    "The signed network in the Reddit dataset is the connections between two subreddits (a community on Reddit). Each connection represents the sentiments of one community towards the other.\n",
    "\n",
    "#### Methods\n",
    "\n",
    "##### Data Collection and Graph Building\n",
    "\n",
    "We shall use the datasets from the above-provided URLs. As the datasets are already clean, we do not need to any preprocessing and build the graphs directly.\n",
    "\n",
    "##### Undirected Analysis (to evaluate 'balance' theory)\n",
    "\n",
    "1. Observe the counts of 4 possible signed triads.\n",
    "2. Observe the frequency of triad occurrence with a random distribution of signs in the network.\n",
    "3. Contrast between the original triad frequency and with random distribution.\n",
    "\n",
    "##### Directed Analysis (to evaluate 'status' theory predictions)\n",
    "\n",
    "1. Observe the frequency of Contextualized links (clink): It's a triple formed when node A and node B have an edge to or from another node X before A and B form an edge between each other.\n",
    "2. Compute the generative baseline and surprise, receptive baseline, and surprise for each type of clink.\n",
    "3. Using the above-computed metrics, check the consistency with Balance and Status theory.\n",
    "\n",
    "##### Perform analysis on edge reciprocation\n",
    "\n",
    "1. Observe the number of reciprocations for each type of edge that is the first connection being positive or negative and reciprocal connection being negative or positive\n",
    "2. Calculate the probability of reciprocation for each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import os, pickle\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "\n",
    "## Functions\n",
    "\n",
    "Here we create functions as they would be commonly used across all the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create a directed graph from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_from_df(dataframe_edges: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    This function accepts the edge list dataframe and returns a directed graph\n",
    "    \n",
    "    :param dataframe_edges (pd.DataFrame): A dataframe with edge lists of a graph\n",
    "    :return rnd_graph (nx.Graph): A directed graph constructed using the edgelist\n",
    "    \"\"\"\n",
    "    \n",
    "    graph = nx.from_pandas_edgelist(dataframe_edges, source='FromNodeId', target='ToNodeId', edge_attr='Sign', create_using=nx.DiGraph())\n",
    "    # create_using=nx.DiGraph() indicates to create a directed graph\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to count number of nodes and edges in a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes_edges(graph: nx.Graph):\n",
    "    \"\"\"\n",
    "    This function accepts the graph and returns the number of nodes and edges in the graph\n",
    "    \n",
    "    :param graph (nx.Graph): The graph to be counted\n",
    "    :return nodes (int): The number of nodes in the graph\n",
    "    :return edges (int): The number of edges in the graph\n",
    "    \"\"\"\n",
    "    \n",
    "    # Number of nodes in the graph\n",
    "    nodes = graph.number_of_nodes()\n",
    "\n",
    "    # Number of edges in the graph\n",
    "    edges = graph.number_of_edges()\n",
    "    \n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to count number of positive and negative edges in a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_edge_signs(graph: nx.Graph):\n",
    "    \"\"\"\n",
    "    This function accepts the graph and returns the percentage of positive and negative edges in the graph\n",
    "    \n",
    "    :param graph (nx.Graph): The graph to be counted\n",
    "    :return positive (int): The percentage of positive edges in the graph\n",
    "    :return negative (int): The percentage of negative edges in the graph\n",
    "    \"\"\"\n",
    "    \n",
    "    # we retrieve the edges of the graph to check the number of positive and negative links\n",
    "    weights = graph.edges(data=True) \n",
    "\n",
    "    # weights is a list of tuples with the first node, second node, and edge attributes. We save the sign attribute to count the number of positive and negative edges.\n",
    "    signs = [attr[2][\"Sign\"] for attr in weights]\n",
    "    \n",
    "    total = len(signs)\n",
    "\n",
    "    # We calculate the number of positive and negative numbers \n",
    "    pos = len(list(filter(lambda x: (x >= 0), signs)))\n",
    "    neg = len(list(filter(lambda x: (x < 0), signs)))\n",
    "    \n",
    "    # The percentage is calculated and rounded to one decimal place as to be consistent with the Table in the paper\n",
    "    positive = round((pos/total)*100,1)\n",
    "    negative = round((neg/total)*100,1)\n",
    "    \n",
    "    \n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to count the number of triads of one of the 4 types shown below in a graph\n",
    "\n",
    "<img src=\"./images/figure_1.png\" width=500 align=\"center\" />\n",
    "\n",
    "##### Logic for calculating the number of triads of one of the 4 types shown below in a graph\n",
    "\n",
    "1. For counting the triads we first convert the Directed graph to an undirected graph.\n",
    "2. Remove any self edges that the nodes have.\n",
    "3. Then we convert the graph into an Adjacency List (AL) representation (Dictionary of dictionaries).\n",
    "4. For each node (primary) in the AL, get the other nodes it is connected to. We obtain this by obtaining the value of the adjacency dictionary with the key as the node.\n",
    "5. For each of the connected nodes (secondary), we get the list of nodes (level 3) it is connected to.\n",
    "6. For each of the connected nodes to the connected node, we check if an edge exists to the primary node. \n",
    "7. If an edge exists, it implies that the triad exists.\n",
    "8. For the triad, we retrieve the edge signs and sum them. The sum indicates the type of traid it is and the count is increased. \n",
    "\n",
    "\n",
    "    A sum of 3 indicates a type T3, a sum of 1 indicates a type T2, a sum of -1 indicates a T1 and finally a sum of -3 indicates a T0.\n",
    "    \n",
    "**As this an expensive calculation, we store the information of nodes and sum of signs in the pickle file and try to return that data if the function is called again. For this, a unique file name has to be provided.**    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triad_tuple(graph: nx.Graph):\n",
    "    \"\"\"\n",
    "    This function accepts the graph and returns the triads in the graph along with the sum of edge signs\n",
    "    \n",
    "    :param graph (nx.Graph): The graph to be counted\n",
    "    :param file_path (str): The path of the file to store/load the triad nodes in a pickle (binary) file.\n",
    "    :return triad_counts (dict): The number of triads of each type in the graph\n",
    "    \"\"\"\n",
    "    \n",
    "    # a list to store the nodes of a triad and the sum of its signs\n",
    "    triad_and_sum = list()\n",
    "    triads = set()\n",
    "\n",
    "    #convert directed graph to undirected graph\n",
    "    undir_graph = graph.to_undirected(reciprocal=False) # Reciprocal is set to false to retain edges that are unidirectional in the directed graph\n",
    "\n",
    "    # remove any self edges\n",
    "    undir_graph.remove_edges_from(nx.selfloop_edges(undir_graph))\n",
    "\n",
    "    adj_list = nx.convert.to_dict_of_dicts(undir_graph)\n",
    "    \n",
    "    for node_1, row in tqdm(adj_list.items()):\n",
    "        for node_2 in row.keys():\n",
    "            for node_3 in adj_list[node_2]:\n",
    "                if node_3 in row:\n",
    "                    if len({node_1, node_2, node_3}) == 3:\n",
    "                        triangle = tuple(sorted((node_1, node_2, node_3)))\n",
    "                        if not triangle in triads:\n",
    "                            triads.add(triangle)\n",
    "                            tri = nx.subgraph(undir_graph, triangle)\n",
    "                            #take the sum of the edge weights. We can decide on the type of the triad based the sum\n",
    "                            tot_sign = sum([x[2]['Sign'] for x in tri.edges(data=True)])\n",
    "                            triad_and_sum.append((triangle, tot_sign))\n",
    "    return triad_and_sum\n",
    "\n",
    "\n",
    "def count_undir_traids(graph: nx.Graph, file_path: str):\n",
    "    \"\"\"\n",
    "    This function accepts the graph and returns the number of triads in the graph for each type in an undirected setting\n",
    "    \n",
    "    :param graph (nx.Graph): The graph to be counted\n",
    "    :param file_path (str): The path of the file to store/load the triad nodes in a pickle (binary) file.\n",
    "    :return triad_counts (dict): The number of triads of each type in the graph\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # empty dictionary to store triad counts\n",
    "    triad_counts = {\"T3\":0, \"T2\":0, \"T1\":0, \"T0\":0}\n",
    "\n",
    "    # a dictionry to indicate the type of triad based on the sum of signs\n",
    "    triad_type = {3:\"T3\", 1:\"T2\", -1:\"T1\", -3:\"T0\"}\n",
    "\n",
    "    # checking if triad list is already available\n",
    "    try:\n",
    "        triad_and_sum = pickle.load(open(file_path+\".pickle\", \"rb\"))\n",
    "    \n",
    "    except IOError:\n",
    "        triad_and_sum = triad_tuple(graph) \n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        with open(file_path+\".pickle\", 'wb') as handle:\n",
    "            pickle.dump(triad_and_sum, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    summed_signs = [trisum[1] for trisum in triad_and_sum]\n",
    "    sum_count = Counter(summed_signs)\n",
    "    triad_counts = {triad_type[sumval]:count for sumval, count in sum_count.items()}\n",
    "\n",
    "\n",
    "    return triad_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to randomise signs in the dataframe according to the proportion of positive and negative signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_df(graph_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    This function accepts the edge list dataframe and returns the dataframe containing the edges with random sign distribution.\n",
    "    \n",
    "    :param graph_df (pd.DataFrame): A dataframe with edge lists of a graph\n",
    "    :return rnd_graph_df (pd.DataFrame): the dataframe with random sign edges\n",
    "    \"\"\"\n",
    "    \n",
    "    rnd_graph_df = graph_df.copy()\n",
    "    rnd_graph_df = rnd_graph_df.sample(frac=1) # shuffle\n",
    "    rnd_graph_df.reset_index(inplace=True, drop=True)\n",
    "    rnd_graph_df['FromNodeId'] = graph_df['FromNodeId']\n",
    "    rnd_graph_df['ToNodeId'] = graph_df['ToNodeId']\n",
    "    rnd_graph_df[\"Time\"] = graph_df['Time']\n",
    "\n",
    "    return rnd_graph_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate the statistics related analysis of undirected graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_undir_surprise(Ti: int, PoTi: float, delta: int):\n",
    "    \"\"\"\n",
    "    This function accepts the number of triads of a type, priori probability of that of the triad and the total number of triads and\n",
    "    returns the surprise.\n",
    "    \n",
    "    :param Ti (int): The number of triads of a type in the graph\n",
    "    :param PoTi (float):  A priori probability of the type of triad\n",
    "    :param delta (int): The total number of triads in the graph\n",
    "    :return surp (float): The surprise which is defined as the number of standard deviations by which the actual quantity of triads of a type differs\n",
    "    from the expected number under the random-shuffling model.\n",
    "    \"\"\"\n",
    "    ETi = PoTi * delta\n",
    "    sup_num = Ti - ETi\n",
    "    sup_den = np.sqrt(ETi*(1-PoTi))\n",
    "    surp = sup_num/sup_den\n",
    "    return surp\n",
    "\n",
    "\n",
    "def get_undirected_metrics(graph_udir_triads: dict, rnd_graph_udir_triads: dict):\n",
    "    \"\"\"\n",
    "    This function accepts the triad count of the graph and the random graph and\n",
    "    returns the Fraction of triads of each type along with the priori probability and the surprise.\n",
    "    \n",
    "    :param graph_udir_triads (dict): The number of triads of each type in the graph\n",
    "    :param rnd_graph_udir_triads (dict): The number of triads of each type in the graph\n",
    "    :return graph_stats (dict): A dictionary containing the information on the number of balanced and unbalanced undirected triads in the graph\n",
    "    \"\"\"\n",
    "    \n",
    "    graph_stats = {}\n",
    "    \n",
    "    delta = sum(graph_udir_triads.values())\n",
    "    graph_stats[\"delta\"] = delta\n",
    "    \n",
    "    for ttype, Ti in graph_udir_triads.items():\n",
    "        \n",
    "        pTi = Ti/delta\n",
    "        poTi = rnd_graph_udir_triads[ttype]/delta\n",
    "        STi = get_undir_surprise(Ti, poTi, delta)\n",
    "        \n",
    "        graph_stats[ttype] = {\"Ti\": Ti, \"pTi\":round(pTi, 3), \"poTi\":round(poTi, 3), \"STi\": round(STi,1)}\n",
    "    \n",
    "    return graph_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate the generative and receptive baseline of each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baselines(graph:nx.DiGraph):\n",
    "    \"\"\"\n",
    "    This function accepts the directed graph and return the generative and receptive baselines for each node.\n",
    "    \n",
    "    :param graph (nx.DiGraph): The directed graph\n",
    "    :return gen_base (dict): A dictionary with keys as node and the values as their generative baselines.\n",
    "    :return rec_base (dict): A dictionary with keys as node and the values as their receptive baselines.\n",
    "    \"\"\"\n",
    "    \n",
    "    # dictionaries to store baselines\n",
    "    gen_base = {}\n",
    "    rec_base = {}\n",
    "    \n",
    "    # for each node\n",
    "    for node in tqdm(graph):\n",
    "        \n",
    "        # get the incoming edges and calculate the generative baseline\n",
    "        try:\n",
    "            inedges = graph.in_edges(node, data=True)\n",
    "            gen_num = sum(in_edge[2][\"Sign\"] for in_edge in inedges if in_edge[2][\"Sign\"] == 1)\n",
    "            gen_base[node] = gen_num/len(inedges)\n",
    "        except:\n",
    "            gen_base[node] =0\n",
    "        \n",
    "        # get the outgoing edges and calculate the recptive baseline\n",
    "        try:\n",
    "            outedges = graph.out_edges(node, data=True)\n",
    "            rec_num = sum(out_edge[2][\"Sign\"] for out_edge in outedges if out_edge[2][\"Sign\"] == 1)\n",
    "            rec_base[node] = rec_num/len(outedges)\n",
    "        except:\n",
    "            rec_base[node] = 0\n",
    "            \n",
    "    return gen_base, rec_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to statistics related to directed graph such as the number of traids of each of the 16 types\n",
    "\n",
    "To analyse the network as it grow, we do not build the entire graph at once, we build edge by edge based on the time they were created.\n",
    "\n",
    "1. We sort the dataframe based on the `Time` column.\n",
    "2. We go over each edge in the dataframe and get the common neighbors between the from node and to node.\n",
    "3. Then, get the type of edges between the to and from node to the common neighbour and update the respective count, generative and receptive base.\n",
    "4. Using the edge sign we assign the status to from node and to node and subsequently append it to the triad type.\n",
    "5. We also append the sign prediction using balance theory to evaluate the balance theory.\n",
    "\n",
    "##### Prediction of edge sign using Balance theory.\n",
    "\n",
    "        According to balance theory triads with three positive signs and one positive sign are more popular than others. Using this we make the prediction as follows\n",
    "        1. If the two edges already existing are positive, then the third edge would be positive.\n",
    "        2. If the two edges already existing are negative, then the third edge would be positive.\n",
    "        3. If there is one positive edge, one negative edge already existing, then the third edge would be negative.\n",
    "\n",
    "   This will make the prediction of edge as positive for triads of type $t_1$, $t_3$, $t_6$, $t_8$, $t_9$, $t_{11}$, $t_{14}$ and $t_{16}$, and negative for remaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directed_stats(edge_dataframe: pd.DataFrame, tri_mapping: dict, gen_base: dict, rec_base: dict):  \n",
    "    \"\"\"\n",
    "    This function accepts the dataframe containing the edges and the Time of edge creation,\n",
    "    the mapping of traid types, generative and receptive bases of nodes and\n",
    "    return the census for each type of the 16 traids in a directed graph.\n",
    "    The census include the number of triads of the specified type,\n",
    "    the number of positive edges created while completing the triad (i.e. A-B edges),\n",
    "    the generative and receptive base of the traid type,\n",
    "    the status of A and B in each of the triad in each triad type.\n",
    "    \n",
    "    :param edge_dataframe (pd.DataFrame): The dataframe with edge list\n",
    "    :param tri_mapping (dict): A dictionary mapping the traid edge attribute to its type.\n",
    "    :param gen_base (dict): A dictionary with keys as node and the values as their generative baselines.\n",
    "    :param rec_base (dict): A dictionary with keys as node and the values as their receptive baselines.\n",
    "    :return dir_graph_stats (dict): A dictionary of dictionary with traid type as first level key and\n",
    "    the count, positive edges, generative base, receptive base, statuses of from node, statuses of to node,\n",
    "    the edge sign predicted using balance theory.\n",
    "    \"\"\"\n",
    "    \n",
    "    # an empty directed graph to store the building graph \n",
    "    dir_graph = nx.DiGraph()\n",
    "    \n",
    "    sorted_dataframe = edge_dataframe.sort_values(by='Time', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    # a dictionary to store the information related to each type of 16 triads\n",
    "    dir_graph_stats = {\"t\"+str(i):{\"tot\":0, \"pos\":0, \"gb\":0,\"rb\":0, \"status_a\": [], \"status_b\": [], \"bal_pred_sign\": []} for i in range(1,17)}\n",
    "    \n",
    "    # building the graph\n",
    "    for rid, row in tqdm(sorted_dataframe.iterrows()):\n",
    "        frm_node = row[\"FromNodeId\"]\n",
    "        to_node = row[\"ToNodeId\"]\n",
    "        sgn = row[\"Sign\"]\n",
    "        \n",
    "        # check if the from node and to node are already in the graph to check for triads\n",
    "        if (frm_node in dir_graph) and (to_node in dir_graph) and (frm_node != to_node):\n",
    "            \n",
    "            # get the neighbors of from node and the to node\n",
    "            frm_nbs = set(dir_graph.successors(frm_node)).union(dir_graph.predecessors(frm_node))\n",
    "            to_nbs = set(dir_graph.successors(to_node)).union(dir_graph.predecessors(to_node))\n",
    "            # get the common neighbors between the from node and to node\n",
    "            cmn_nbs = set(frm_nbs.intersection(to_nbs))\n",
    "            \n",
    "            for nbr in cmn_nbs:\n",
    "                # check and ignore self loops for from node and to node\n",
    "                if nbr not in [frm_node, to_node]:\n",
    "                    # the two lists stores the direction and sign of the connection between common neighbour and from and to nodes.\n",
    "                    frm_nbr = []\n",
    "                    to_nbr = []\n",
    "\n",
    "                    # check if the connection is originating from the from (to) node or neighbour\n",
    "                    if dir_graph.has_edge(frm_node, nbr):\n",
    "                        frm_nbr.append((\"fs\", dir_graph.get_edge_data(frm_node, nbr)[\"Sign\"]))\n",
    "                    if dir_graph.has_edge(nbr, frm_node):\n",
    "                        frm_nbr.append((\"fr\", dir_graph.get_edge_data(nbr, frm_node)[\"Sign\"]))\n",
    "\n",
    "                    if dir_graph.has_edge(to_node, nbr):\n",
    "                        to_nbr.append((\"ts\", dir_graph.get_edge_data(to_node, nbr)[\"Sign\"]))\n",
    "                    if dir_graph.has_edge(nbr, to_node):\n",
    "                        to_nbr.append((\"tr\", dir_graph.get_edge_data(nbr, to_node)[\"Sign\"]))\n",
    "\n",
    "                    for from_type in frm_nbr:\n",
    "                        for to_type in to_nbr:\n",
    "                            # get the type of triad\n",
    "                            tri_type = tri_mapping[frozenset([from_type, to_type])]\n",
    "                            # increase the count of the triad type\n",
    "                            dir_graph_stats[tri_type][\"tot\"] += 1 \n",
    "                            # if the sign of the to be formed link is positive, increase the count of positive links for the type of c-link\n",
    "                            if sgn == 1:\n",
    "                                dir_graph_stats[tri_type][\"pos\"] += 1\n",
    "                            # add the generative (receptive) base line of from (to) node to the triad type \n",
    "                            dir_graph_stats[tri_type][\"gb\"] += gen_base[frm_node]\n",
    "                            dir_graph_stats[tri_type][\"rb\"] += rec_base[to_node]\n",
    "\n",
    "                            # status of from node\n",
    "                            if from_type in [(\"fr\",1), (\"fs\",-1)]:\n",
    "                                dir_graph_stats[tri_type][\"status_a\"].append(1)\n",
    "                            else:\n",
    "                                dir_graph_stats[tri_type][\"status_a\"].append(-1)\n",
    "\n",
    "                            # status of to node\n",
    "                            if from_type in [(\"tr\",1), (\"ts\",-1)]:\n",
    "                                dir_graph_stats[tri_type][\"status_b\"].append(1)\n",
    "                            else:\n",
    "                                dir_graph_stats[tri_type][\"status_b\"].append(-1)\n",
    "                            \n",
    "                            # prediction using balance theory\n",
    "                            if tri_type in [\"t1\", \"t3\", \"t6\", \"t8\", \"t9\", \"t11\", \"t14\", \"t16\"]:\n",
    "                                dir_graph_stats[tri_type][\"bal_pred_sign\"].append(1)\n",
    "                            else:\n",
    "                                dir_graph_stats[tri_type][\"bal_pred_sign\"].append(-1)\n",
    "                                \n",
    "        dir_graph.add_edge(frm_node, to_node, Sign=sgn)\n",
    "    return dir_graph_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate the probability of a positive edge in directed graph.\n",
    "\n",
    "We calculate the probability of positive edges by dividing the number of positive edges by total number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posprob(dir_graph_stats: dict):\n",
    "    \"\"\"\n",
    "    This function accepts the stats related to a directed graph and return the probability of positive edges\n",
    "    \n",
    "    :param dir_graph_stats (dict): A dictionary of dictionary with traid type as first level key and\n",
    "    the count, positive edges, generative base, receptive base, statuses of from node, statuses of to node.\n",
    "    :return pos_prob (dict): A dictionary with keys as triad type and the values as probability of positive edge in the triad.\n",
    "    \"\"\"\n",
    "    \n",
    "    pos_prob = {ttype: dir_graph_stats[ttype][\"pos\"]/dir_graph_stats[ttype][\"tot\"] for ttype in dir_graph_stats}\n",
    "    return pos_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate the generative and receptive surprise in each type of triad and respective evaluation of Balance and Status theories\n",
    "\n",
    "We shall follow a similar procedure used for undirected graph except that here the calculation is for the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directed_evaluation(dir_graph_stats: dict, pos_prob: dict):\n",
    "    \"\"\"\n",
    "    This function accepts the stats related to a directed graph, the aprori probablity of having a positive edge\n",
    "    and return the probability of having a positive edge in a triad,generative surprise and receptive surprise.\n",
    "    \n",
    "    :param dir_graph_stats (dict): A dictionary of dictionary with traid type as first level key and\n",
    "    the count, positive edges, generative base, receptive base, statuses of from node, statuses of to node.\n",
    "    :param pos_prob (dict): A dictionary with keys as triad type and the values as probability of positive edge in the triad.\n",
    "    :return dir_graph_surp (dict): A dictionary of dictionary with traid type as first level key and\n",
    "    the probability of positive edges, generative surprise, receptive surprise, booleans indicating\n",
    "    consistency of balance with generative surprise,\n",
    "    consistency of balance with receptive surprise,\n",
    "    consistency of status with generative surprise,\n",
    "    consistency of status with receptive surprise.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_surp(total, expected, p_prob):\n",
    "        sup_num = total - expected\n",
    "        sup_den = np.sqrt(expected*(1-p_prob))\n",
    "        surp = sup_num/sup_den\n",
    "        return surp\n",
    "    \n",
    "    dir_graph_surp = {}\n",
    "    for ttype, tprop in dir_graph_stats.items():\n",
    "        dir_graph_surp[ttype] = {}\n",
    "        dir_graph_surp[ttype][\"count\"] = tprop[\"tot\"]\n",
    "        dir_graph_surp[ttype][\"P+\"] = round(tprop[\"pos\"]/tprop[\"tot\"],2)\n",
    "        \n",
    "        # gen_surp denotes the generative surprise\n",
    "        gen_surp = get_surp(tprop[\"tot\"], tprop[\"gb\"], pos_prob[ttype])\n",
    "        dir_graph_surp[ttype][\"gen_surp\"] = round(gen_surp, 1)\n",
    "        \n",
    "        # consistency of status with generative surprise,\n",
    "        if np.sign(gen_surp) == np.sign(np.prod(tprop[\"status_b\"])):\n",
    "            sg = True\n",
    "        else:\n",
    "            sg = False\n",
    "        \n",
    "        dir_graph_surp[ttype][\"sg\"] = sg\n",
    "        \n",
    "        # consistency of balance with generative surprise,\n",
    "        if np.sign(gen_surp) == np.sign(np.prod(tprop[\"bal_pred_sign\"])):\n",
    "            bg = True\n",
    "        else:\n",
    "            bg = False\n",
    "            \n",
    "        dir_graph_surp[ttype][\"bg\"] = bg\n",
    "            \n",
    "        # rec_surp denotes the receptive surprise\n",
    "        rec_surp = get_surp(tprop[\"tot\"], tprop[\"rb\"], pos_prob[ttype])\n",
    "        dir_graph_surp[ttype][\"rec_surp\"] = round(rec_surp, 1)\n",
    "        \n",
    "        # consistency of status with receptive surprise,\n",
    "        if np.sign(rec_surp) != np.sign(np.prod(tprop[\"status_a\"])):\n",
    "            sr = True\n",
    "        else:\n",
    "            sr = False\n",
    "        \n",
    "        dir_graph_surp[ttype][\"sr\"] = sr\n",
    "        \n",
    "        # consistency of balance with receptive surprise,\n",
    "        if np.sign(rec_surp) == np.sign(np.prod(tprop[\"bal_pred_sign\"])):\n",
    "            br = True\n",
    "        else:\n",
    "            br = False\n",
    "        \n",
    "        dir_graph_surp[ttype][\"br\"] = br\n",
    "        \n",
    "    return dir_graph_surp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis of the network as a directed graph, we need to count the 16 types of traids as shown in the figure below.\n",
    "\n",
    "\n",
    "<img src=\"./images/figure_2.png\" width=350 align=\"center\" />\n",
    "\n",
    "We call the `A` node as from node, `B` node as to node (as the triad is generated by forming the edge from `A` to `B`) and `X` as common neighbor. If the `from node` is receiving connection from the common neighbor, we shall name it \"fr\" and \"fs\" in the opposite case. Similarly, if the `to node` is receiving connection from common neighbor, we shall name it \"tr\" and \"ts\" in the opposite case.\n",
    "\n",
    "Below we store this mapping in a dictionary. As each traid is represented by two attributes, we will use a frozen set of the from attribute and to attribute as the key of the dictionary. The reason for using frozen set is it is hashable because it's immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_mapping = {frozenset([(\"fs\",1),(\"tr\",1)]):\"t1\",\n",
    "              frozenset([(\"fs\",1),(\"tr\",-1)]):\"t2\",\n",
    "              frozenset([(\"fs\",1),(\"ts\",1)]):\"t3\",\n",
    "              frozenset([(\"fs\",1),(\"ts\",-1)]):\"t4\",\n",
    "              frozenset([(\"fs\",-1),(\"tr\",1)]):\"t5\",\n",
    "              frozenset([(\"fs\",-1),(\"tr\",-1)]):\"t6\",\n",
    "              frozenset([(\"fs\",-1),(\"ts\",1)]):\"t7\",\n",
    "              frozenset([(\"fs\",-1),(\"ts\",-1)]):\"t8\",\n",
    "              frozenset([(\"fr\",1),(\"tr\",1)]):\"t9\",\n",
    "              frozenset([(\"fr\",1),(\"tr\",-1)]):\"t10\",\n",
    "              frozenset([(\"fr\",1),(\"ts\",1)]):\"t11\",\n",
    "              frozenset([(\"fr\",1),(\"ts\",-1)]):\"t12\",\n",
    "              frozenset([(\"fr\",-1),(\"tr\",1)]):\"t13\",\n",
    "              frozenset([(\"fr\",-1),(\"tr\",-1)]):\"t14\",\n",
    "              frozenset([(\"fr\",-1),(\"ts\",1)]):\"t15\",\n",
    "              frozenset([(\"fr\",-1),(\"ts\",-1)]):\"t16\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>\n",
    "\n",
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BitCoin Alpha Dataset\n",
    "\n",
    "#### Dataset Description\n",
    "\n",
    "The signed network in the bitcoin transaction dataset is created by users trading Bitcoins, who rate other members on a scale of -10 (total distrust) to +10 (total trust) to prevent transactions with fraudulent and risky users. The data is stored in a compressed csv file with no headers. There are four columns in the dataset and they are the source node, desination node, the trust value and the time of creation of the edge.\n",
    "\n",
    "As our analysis relates to sign of the edge rather than the numerical value, we consider all the trust values less than 0 are -1 and the remaining as +1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sign(weight):\n",
    "    if weight < 0:\n",
    "        return -1\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the graph\n",
    "\n",
    "As the csv file does not have any header, we skip the header and provide names to the columns and create a directed graph using the dataframe as edge list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the data to the dataframe\n",
    "bitcoin_df = pd.read_csv(\"./data/soc-sign-bitcoinalpha.csv.gz\", header=None, names=[\"FromNodeId\", \"ToNodeId\", \"Sign\", \"Time\"])\n",
    "bitcoin_df['Sign'] = bitcoin_df['Sign'].map(get_sign)\n",
    "\n",
    "bitcoin_graph = create_graph_from_df(bitcoin_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in slashdot network are 3783\n",
      "The number of edges in slashdot network are 24186\n",
      "\n",
      "The percentage of positive edges in the slashdot network is 93.6\n",
      "The percentage of negative edges in the slashdot network is 6.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Counting Nodes and Edges in Bitcoin Alpha network\n",
    "bitcoin_nodes, bitcoin_edges = count_nodes_edges(bitcoin_graph)\n",
    "print(\"The number of nodes in slashdot network are {0}\".format(bitcoin_nodes))\n",
    "print(\"The number of edges in slashdot network are {0}\".format(bitcoin_edges))\n",
    "print()\n",
    "## Counting the signs of the Edges in Bitcoin Alpha network\n",
    "bitcoin_pos_edges, bitcoin_neg_edges = count_edge_signs(bitcoin_graph)\n",
    "print(\"The percentage of positive edges in the slashdot network is {0}\".format(bitcoin_pos_edges))\n",
    "print(\"The percentage of negative edges in the slashdot network is {0}\".format(bitcoin_neg_edges))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the Bitcoin network as an undirected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Triads in slashdot network are 22153\n"
     ]
    }
   ],
   "source": [
    "# Counting the traids of each type in undirected Bitcoin Alpha network\n",
    "bitcoin_undir_triads = count_undir_traids(bitcoin_graph, \"./data/cache/bitcoinalpha_undir_triad\")\n",
    "\n",
    "# creating a Bitcoin Alpha graph with randomised edge signs\n",
    "rnd_bitcoin_graph_df = randomize_df(bitcoin_df)\n",
    "rnd_bitcoin_graph = create_graph_from_df(rnd_bitcoin_graph_df)\n",
    "\n",
    "# Counting the traids of each type in undirected Bitcoin Alpha network with randomised edge signs\n",
    "rnd_bitcoin_undir_triads = count_undir_traids(rnd_bitcoin_graph, \"./data/cache/rnd_bitcoinalpha_undir_triad\")\n",
    "\n",
    "bitcoin_graph_stats = get_undirected_metrics(bitcoin_undir_triads, rnd_bitcoin_undir_triads)\n",
    "\n",
    "print(\"The number of Triads in slashdot network are {0}\".format(bitcoin_graph_stats[\"delta\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin Alpha Dataset Statitics\n",
      "+--------+---------------+\n",
      "|        | Bitcoin Alpha |\n",
      "+--------+---------------+\n",
      "| Nodes  |      3783     |\n",
      "| Edges  |     24186     |\n",
      "| +Edges |      93.6     |\n",
      "| -Edges |      6.4      |\n",
      "| Triads |     22153     |\n",
      "+--------+---------------+\n",
      "\n",
      "\n",
      "Analysis of Undirected Bitcoin Alpha Dataset\n",
      "+------------+-------+-------+--------+-------+\n",
      "| Triad Ti   |  |Ti| | P(Ti) | Po(Ti) | S(Ti) |\n",
      "+------------+-------+-------+--------+-------+\n",
      "| T3 | + + + | 17014 | 0.768 | 0.815  | -18.1 |\n",
      "| T1 | + - - |  1667 | 0.075 | 0.012  |  84.5 |\n",
      "| T2 | + + - |  3333 |  0.15 | 0.172  |  -8.6 |\n",
      "| T0 | - - - |  139  | 0.006 |  0.0   |  59.9 |\n",
      "+------------+-------+-------+--------+-------+\n"
     ]
    }
   ],
   "source": [
    "btc_stats_table = PrettyTable()\n",
    "print(\"Bitcoin Alpha Dataset Statitics\")\n",
    "btc_stats_table.field_names = [\" \", \"Bitcoin Alpha\"]\n",
    "btc_stats_table.add_row([\"Nodes\", bitcoin_nodes])\n",
    "btc_stats_table.add_row([\"Edges\", bitcoin_edges])\n",
    "btc_stats_table.add_row([\"+Edges\", bitcoin_pos_edges])\n",
    "btc_stats_table.add_row([\"-Edges\", bitcoin_neg_edges])\n",
    "btc_stats_table.add_row([\"Triads\",  bitcoin_graph_stats[\"delta\"]])\n",
    "print(btc_stats_table)\n",
    "print(\"\\n\")\n",
    "\n",
    "btc_undir_table = PrettyTable()\n",
    "print(\"Analysis of Undirected Bitcoin Alpha Dataset\")\n",
    "btc_undir_table.field_names = [\"Triad Ti \", \"|Ti|\", \"P(Ti)\", \"Po(Ti)\", \"S(Ti)\"]\n",
    "btc_undir_table.add_row([\"T3 | + + +\", bitcoin_graph_stats[\"T3\"][\"Ti\"], bitcoin_graph_stats[\"T3\"][\"pTi\"], bitcoin_graph_stats[\"T3\"][\"poTi\"], bitcoin_graph_stats[\"T3\"][\"STi\"]])\n",
    "btc_undir_table.add_row([\"T1 | + - -\", bitcoin_graph_stats[\"T1\"][\"Ti\"], bitcoin_graph_stats[\"T1\"][\"pTi\"], bitcoin_graph_stats[\"T1\"][\"poTi\"], bitcoin_graph_stats[\"T1\"][\"STi\"]])\n",
    "btc_undir_table.add_row([\"T2 | + + -\", bitcoin_graph_stats[\"T2\"][\"Ti\"], bitcoin_graph_stats[\"T2\"][\"pTi\"], bitcoin_graph_stats[\"T2\"][\"poTi\"], bitcoin_graph_stats[\"T2\"][\"STi\"]])\n",
    "btc_undir_table.add_row([\"T0 | - - -\", bitcoin_graph_stats[\"T0\"][\"Ti\"], bitcoin_graph_stats[\"T0\"][\"pTi\"], bitcoin_graph_stats[\"T0\"][\"poTi\"], bitcoin_graph_stats[\"T0\"][\"STi\"]])\n",
    "print(btc_undir_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion\n",
    "\n",
    "The triads for this network can be interpreted as below\n",
    "- $T_3$: If two users trust a common user then they trust each other.\n",
    "- $T_1$: If two users distrust a common user then they trust each other.\n",
    "- $T_2$: If two users trust a common user then they distrust each other.\n",
    "- $T_0$: If two users distrust a common user then they distrust each other.\n",
    "\n",
    "We find that the all-positive triad $T_3$, two-positive triad $T_2$ are underrepresented, and the triads of type $T_1$ and $T_0$ are overrepresented. This phenomena cannot be explanied by both Heider’s original notion of structural balance and Davis’s weaker notion of balance. \n",
    "\n",
    "<hr style=\"border:1px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the Bitcoin network as an evolving directed network\n",
    "\n",
    "Using the already created graph, we obtain the generative and recptive baselines for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f0c5be20ba4f0d9b694eeff034c169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3783.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "btc_genbase, btc_recbase = get_baselines(bitcoin_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the census realted to the directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06b6bc6d6b94c84aa9dbe21db992aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "btc_dirgraph_stats = get_directed_stats(bitcoin_df, tri_mapping, btc_genbase, btc_recbase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the surprise i.e. the number of standard deviations by which the actual number of positive A-B edges for a triad differs above or below the number obatined through the bases we need the priori probability of having a positive edge for each the traid type. For this, we shall keep the edge sequence and order the same and randomise the edge sign while maintaining the number of positive and negative signs. This is already obtained while performing the analysis on undirected graph and we shall use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab62aec5e7ca45cc9bfeb045f42367d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the census realted to the randomised directed graph\n",
    "# As we only need the number of positive edges for each type of triad and do not bother about other attributes, we use the ols generative and receptive bases\n",
    "btc_rnd_dirgraph_stats = get_directed_stats(rnd_bitcoin_graph_df, tri_mapping, btc_genbase, btc_recbase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the information on number of positive edges in each type of traid, obtained by randomised sign graph. We get the priori probability of having a positive edge for each triad type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_PoTi = get_posprob(btc_rnd_dirgraph_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with respect to balance and status theories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_eval = directed_evaluation(btc_dirgraph_stats, btc_PoTi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ti \t count \t P(+) \t sg \t sr \t Bg \t Br \t Sg \t Sr\n",
      "--------------------------------------------------------------------------------\n",
      "t1 \t 26910 \t 0.92 \t 28.9 \t 61.8 \t True \t True \t True \t False\n",
      "t2 \t 1105 \t 0.22 \t 12.2 \t 25.9 \t False \t False \t False \t True\n",
      "t3 \t 27368 \t 0.9 \t 28.7 \t 52.7 \t True \t True \t True \t False\n",
      "t4 \t 709 \t 0.67 \t 15.1 \t 24.3 \t False \t False \t False \t True\n",
      "t5 \t 1272 \t 0.67 \t 14.6 \t 22.7 \t True \t True \t True \t False\n",
      "t6 \t 201 \t 0.61 \t 6.5 \t 11.1 \t True \t True \t False \t False\n",
      "t7 \t 950 \t 0.57 \t 13.9 \t 18.3 \t True \t True \t True \t False\n",
      "t8 \t 900 \t 0.83 \t 8.0 \t 17.0 \t True \t True \t True \t False\n",
      "t9 \t 27563 \t 0.92 \t 25.6 \t 62.3 \t True \t True \t False \t False\n",
      "t10 \t 1121 \t 0.21 \t 10.6 \t 24.6 \t False \t False \t False \t False\n",
      "t11 \t 26497 \t 0.9 \t 23.9 \t 50.7 \t True \t True \t False \t False\n",
      "t12 \t 1020 \t 0.75 \t 10.5 \t 24.9 \t True \t True \t True \t False\n",
      "t13 \t 475 \t 0.59 \t 34.5 \t 14.5 \t False \t False \t False \t True\n",
      "t14 \t 179 \t 0.63 \t 42.1 \t 18.5 \t True \t True \t False \t True\n",
      "t15 \t 475 \t 0.56 \t 36.8 \t 12.5 \t False \t False \t False \t True\n",
      "t16 \t 159 \t 0.81 \t 15.5 \t 15.0 \t True \t True \t False \t True\n"
     ]
    }
   ],
   "source": [
    "print(\"ti\", \"\\t\", \"count\", \"\\t\", \"P(+)\", \"\\t\", \"sg\", \"\\t\", \"sr\", \"\\t\", \"Bg\", \"\\t\", \"Br\", \"\\t\", \"Sg\", \"\\t\", \"Sr\")\n",
    "print(\"-\"*80)\n",
    "for i,j in btc_eval.items():\n",
    "    print(i, \"\\t\", j[\"count\"], \"\\t\", j[\"P+\"], \"\\t\", j[\"gen_surp\"], \"\\t\", j[\"rec_surp\"], \"\\t\", j[\"bg\"], \"\\t\", j[\"br\"], \"\\t\", j[\"sg\"], \"\\t\", j[\"sr\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Hyperlink Network Dataset\n",
    "\n",
    "#### Dataset Description\n",
    "\n",
    "The signed network in the Reddit dataset is the connections between two subreddits (a community on Reddit). Each connection represents the sentiments of one community towards the other in one post. Thus, there will be many connections from one subbredit to other. We merge all the edges from one subreddit to other and take the majority sign as the sign of the edge between them. The data is stored in a tsv file with `SOURCE_SUBREDDIT, TARGET_SUBREDDIT, POST_ID, TIMESTAMP, LINK_SENTIMENT, PROPERTIES` as headers. We ignore the POST_ID and PROPERTIES as we deal only with the sign of the edge. The *SOURCE_SUBREDDIT* will be the from node, *TARGET_SUBREDDIT* will be the to node, *LINK_SENTIMENT* which is 1 or -1 will be the edge sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the graph\n",
    "\n",
    "As the tsv file has a header, we skip the columns we do not need and create the dataframe.\n",
    "\n",
    "We store the information about the edges in a dictionary of dictionaries. The first level key is the from node, second level key will be the to node and the values be the sign of the edge and the time stamp of last created link.\n",
    "\n",
    "We create a dictionary to store the sub reddit name mapped to a unique interger asnetworkx works well with integer node ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data to the dataframe\n",
    "reddit_df_full = pd.read_csv(\"./data/soc-redditHyperlinks-body.tsv\", sep=\"\\t\", usecols=[\"SOURCE_SUBREDDIT\", \"TARGET_SUBREDDIT\", \"TIMESTAMP\", \"LINK_SENTIMENT\"])\n",
    "\n",
    "# empty dictionary to store the network\n",
    "reddit_adj_list = {}\n",
    "\n",
    "for _, edge in reddit_df_full.iterrows():\n",
    "    from_node = edge[\"SOURCE_SUBREDDIT\"]\n",
    "    to_node = edge[\"TARGET_SUBREDDIT\"]\n",
    "    if from_node not in reddit_adj_list:\n",
    "        reddit_adj_list[from_node] = {}\n",
    "    if to_node not in reddit_adj_list[from_node]:\n",
    "        reddit_adj_list[from_node][to_node] = {\"Sign\": 1, \"Time\":None}\n",
    "    reddit_adj_list[from_node][to_node][\"Sign\"] *= edge[\"LINK_SENTIMENT\"]\n",
    "    reddit_adj_list[from_node][to_node][\"Time\"] = edge[\"TIMESTAMP\"]\n",
    "    \n",
    "# convert the dictionary back into dataframe to reuse the function created.\n",
    "reddit_list = []\n",
    "for from_node, to_nodes in reddit_adj_list.items():\n",
    "    for to_node, edges in to_nodes.items():\n",
    "        reddit_list.append([from_node, to_node, edges[\"Sign\"], edges[\"Time\"]])\n",
    "        \n",
    "col_names = [\"FromNodeId\", \"ToNodeId\", \"Sign\", \"Time\"]\n",
    "reddit_df = pd.DataFrame(data=reddit_list, columns =col_names)\n",
    "# convert the Time from string to datetime format\n",
    "reddit_df[\"Time\"] = pd.to_datetime(reddit_df[\"Time\"])\n",
    "\n",
    "#creation of unique mapping between the subreddit name to a integer.\n",
    "all_nodes = set(reddit_df.FromNodeId.unique()).union(set(reddit_df.ToNodeId.unique()))\n",
    "node_int_map = {node: node_id for node_id, node in enumerate(all_nodes)}\n",
    "reddit_df['FromNodeId'] = reddit_df['FromNodeId'].map(node_int_map)\n",
    "reddit_df['ToNodeId'] = reddit_df['ToNodeId'].map(node_int_map)\n",
    "\n",
    "# creation of the graph\n",
    "reddit_graph = create_graph_from_df(reddit_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes in Reddit Hyperlink Network are 35776\n",
      "The number of edges in Reddit Hyperlink Network are 137821\n",
      "\n",
      "The percentage of positive edges in the Reddit Hyperlink Network is 90.7\n",
      "The percentage of negative edges in the Reddit Hyperlink Network is 9.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Counting Nodes and Edges in Reddit Hyperlink Network\n",
    "reddit_nodes, reddit_edges = count_nodes_edges(reddit_graph)\n",
    "print(\"The number of nodes in Reddit Hyperlink Network are {0}\".format(reddit_nodes))\n",
    "print(\"The number of edges in Reddit Hyperlink Network are {0}\".format(reddit_edges))\n",
    "print()\n",
    "## Counting the signs of the Edges in Reddit Hyperlink Network\n",
    "reddit_pos_edges, reddit_neg_edges = count_edge_signs(reddit_graph)\n",
    "print(\"The percentage of positive edges in the Reddit Hyperlink Network is {0}\".format(reddit_pos_edges))\n",
    "print(\"The percentage of negative edges in the Reddit Hyperlink Network is {0}\".format(reddit_neg_edges))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the Bitcoin network as an undirected network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Triads in Reddit Hyperlink Network are 406391\n"
     ]
    }
   ],
   "source": [
    "# Counting the traids of each type in undirected Reddit Hyperlink Network\n",
    "reddit_undir_triads = count_undir_traids(reddit_graph, \"./data/cache/reddit_undir_triad\")\n",
    "\n",
    "# creating a Reddit Hyperlink Network graph with randomised edge signs\n",
    "rnd_reddit_graph_df = randomize_df(reddit_df)\n",
    "rnd_reddit_graph = create_graph_from_df(rnd_reddit_graph_df)\n",
    "\n",
    "# Counting the traids of each type in undirected Reddit Hyperlink Network with randomised edge signs\n",
    "rnd_reddit_undir_triads = count_undir_traids(rnd_reddit_graph, \"./data/cache/rnd_reddit_undir_triad\")\n",
    "\n",
    "reddit_graph_stats = get_undirected_metrics(reddit_undir_triads, rnd_reddit_undir_triads)\n",
    "\n",
    "print(\"The number of Triads in Reddit Hyperlink Network are {0}\".format(reddit_graph_stats[\"delta\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit Hyperlink Network Statitics\n",
      "+--------+------------------+\n",
      "|        | Reddit Hyperlink |\n",
      "+--------+------------------+\n",
      "| Nodes  |      35776       |\n",
      "| Edges  |      137821      |\n",
      "| +Edges |       90.7       |\n",
      "| -Edges |       9.3        |\n",
      "| Triads |      406391      |\n",
      "+--------+------------------+\n",
      "\n",
      "\n",
      "Analysis of Undirected Reddit Hyperlink Network\n",
      "+------------+--------+-------+--------+--------+\n",
      "| Triad Ti   |  |Ti|  | P(Ti) | Po(Ti) | S(Ti)  |\n",
      "+------------+--------+-------+--------+--------+\n",
      "| T3 | + + + | 221051 | 0.544 | 0.748  | -299.0 |\n",
      "| T1 | + - - | 42060  | 0.103 | 0.023  | 337.3  |\n",
      "| T2 | + + - | 138026 |  0.34 | 0.228  | 169.4  |\n",
      "| T0 | - - - |  5254  | 0.013 | 0.001  | 273.5  |\n",
      "+------------+--------+-------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "btc_stats_table = PrettyTable()\n",
    "print(\"Reddit Hyperlink Network Statitics\")\n",
    "btc_stats_table.field_names = [\" \", \"Reddit Hyperlink\"]\n",
    "btc_stats_table.add_row([\"Nodes\", reddit_nodes])\n",
    "btc_stats_table.add_row([\"Edges\", reddit_edges])\n",
    "btc_stats_table.add_row([\"+Edges\", reddit_pos_edges])\n",
    "btc_stats_table.add_row([\"-Edges\", reddit_neg_edges])\n",
    "btc_stats_table.add_row([\"Triads\",  reddit_graph_stats[\"delta\"]])\n",
    "print(btc_stats_table)\n",
    "print(\"\\n\")\n",
    "\n",
    "btc_undir_table = PrettyTable()\n",
    "print(\"Analysis of Undirected Reddit Hyperlink Network\")\n",
    "btc_undir_table.field_names = [\"Triad Ti \", \"|Ti|\", \"P(Ti)\", \"Po(Ti)\", \"S(Ti)\"]\n",
    "btc_undir_table.add_row([\"T3 | + + +\", reddit_graph_stats[\"T3\"][\"Ti\"], reddit_graph_stats[\"T3\"][\"pTi\"], reddit_graph_stats[\"T3\"][\"poTi\"], reddit_graph_stats[\"T3\"][\"STi\"]])\n",
    "btc_undir_table.add_row([\"T1 | + - -\", reddit_graph_stats[\"T1\"][\"Ti\"], reddit_graph_stats[\"T1\"][\"pTi\"], reddit_graph_stats[\"T1\"][\"poTi\"], reddit_graph_stats[\"T1\"][\"STi\"]])\n",
    "btc_undir_table.add_row([\"T2 | + + -\", reddit_graph_stats[\"T2\"][\"Ti\"], reddit_graph_stats[\"T2\"][\"pTi\"], reddit_graph_stats[\"T2\"][\"poTi\"], reddit_graph_stats[\"T2\"][\"STi\"]])\n",
    "btc_undir_table.add_row([\"T0 | - - -\", reddit_graph_stats[\"T0\"][\"Ti\"], reddit_graph_stats[\"T0\"][\"pTi\"], reddit_graph_stats[\"T0\"][\"poTi\"], reddit_graph_stats[\"T0\"][\"STi\"]])\n",
    "print(btc_undir_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion\n",
    "\n",
    "The triads for this network can be interpreted similar to the friendship.\n",
    "\n",
    "We find that the all-positive triad $T_3$ is underrepresented, and the triads of type $T_2$, $T_1$ and $T_0$ are overrepresented. This phenomena cannot be explanied by both Heider’s original notion of structural balance and Davis’s weaker notion of balance. \n",
    "\n",
    "<hr style=\"border:1px solid black\"> </hr>\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the Reddit Hyperlink Network as an evolving directed network\n",
    "\n",
    "Using the already created graph, we obtain the generative and recptive baselines for each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90121af13316418781e3c5843c753d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35776.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reddit_genbase, reddit_recbase = get_baselines(reddit_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the census realted to the directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f11b813615423185b092775d861afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reddit_dirgraph_stats = get_directed_stats(reddit_df, tri_mapping, reddit_genbase, reddit_recbase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the surprise i.e. the number of standard deviations by which the actual number of positive A-B edges for a triad differs above or below the number obatined through the bases we need the priori probability of having a positive edge for each the traid type. For this, we shall keep the edge sequence and order the same and randomise the edge sign while maintaining the number of positive and negative signs. This is already obtained while performing the analysis on undirected graph and we shall use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f6c35fee7f4431804b9888397f8868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the census realted to the randomised directed graph\n",
    "# As we only need the number of positive edges for each type of triad and do not bother about other attributes, we use the ols generative and receptive bases\n",
    "reddit_rnd_dirgraph_stats = get_directed_stats(rnd_reddit_graph_df, tri_mapping, reddit_genbase, reddit_recbase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the information on number of positive edges in each type of traid, obtained by randomised sign graph. We get the priori probability of having a positive edge for each triad type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_PoTi = get_posprob(reddit_rnd_dirgraph_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation with respect to balance and status theories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_eval = directed_evaluation(reddit_dirgraph_stats, reddit_PoTi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ti \t count \t P(+) \t sg \t sr \t Bg \t Br \t Sg \t Sr\n",
      "--------------------------------------------------------------------------------\n",
      "t1 \t 153237 \t 0.77 \t 200.4 \t 212.1 \t True \t True \t False \t True\n",
      "t2 \t 28025 \t 0.7 \t 97.7 \t 119.2 \t False \t False \t False \t True\n",
      "t3 \t 143721 \t 0.8 \t 185.2 \t 147.9 \t True \t True \t False \t True\n",
      "t4 \t 24897 \t 0.73 \t 93.5 \t 117.7 \t False \t False \t False \t True\n",
      "t5 \t 31139 \t 0.63 \t 116.6 \t 111.0 \t False \t False \t False \t False\n",
      "t6 \t 7833 \t 0.61 \t 65.7 \t 72.3 \t True \t True \t False \t False\n",
      "t7 \t 28787 \t 0.66 \t 111.3 \t 89.7 \t False \t False \t False \t False\n",
      "t8 \t 7563 \t 0.64 \t 66.2 \t 81.4 \t True \t True \t False \t False\n",
      "t9 \t 156890 \t 0.78 \t 147.5 \t 199.2 \t True \t True \t True \t False\n",
      "t10 \t 28395 \t 0.71 \t 77.0 \t 112.3 \t False \t False \t False \t False\n",
      "t11 \t 75606 \t 0.82 \t 91.8 \t 93.1 \t True \t True \t True \t False\n",
      "t12 \t 9722 \t 0.74 \t 42.8 \t 71.5 \t True \t True \t True \t False\n",
      "t13 \t 23566 \t 0.7 \t 90.3 \t 89.9 \t True \t True \t True \t False\n",
      "t14 \t 8754 \t 0.67 \t 59.7 \t 63.6 \t True \t True \t True \t False\n",
      "t15 \t 9968 \t 0.73 \t 56.6 \t 45.4 \t True \t True \t True \t False\n",
      "t16 \t 2049 \t 0.67 \t 30.1 \t 38.1 \t True \t True \t False \t True\n"
     ]
    }
   ],
   "source": [
    "print(\"ti\", \"\\t\", \"count\", \"\\t\", \"P(+)\", \"\\t\", \"sg\", \"\\t\", \"sr\", \"\\t\", \"Bg\", \"\\t\", \"Br\", \"\\t\", \"Sg\", \"\\t\", \"Sr\")\n",
    "print(\"-\"*80)\n",
    "for i,j in reddit_eval.items():\n",
    "    print(i, \"\\t\", j[\"count\"], \"\\t\", j[\"P+\"], \"\\t\", j[\"gen_surp\"], \"\\t\", j[\"rec_surp\"], \"\\t\", j[\"bg\"], \"\\t\", j[\"br\"], \"\\t\", j[\"sg\"], \"\\t\", j[\"sr\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
